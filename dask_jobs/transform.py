import dask.dataframe as dd
import pandas as pd
from dask.distributed import Client
import numpy as np

class MOEXDataProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Dask"""
    
    def __init__(self, input_file, use_dask_cluster=False, scheduler_address=None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        
        input_file: –ø—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É
        use_dask_cluster: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ Dask –∫–ª–∞—Å—Ç–µ—Ä
        scheduler_address: –∞–¥—Ä–µ—Å Dask scheduler (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'localhost:8786')
        """
        self.use_dask_cluster = use_dask_cluster
        self.client = None
        
        if use_dask_cluster and scheduler_address:
            try:
                # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Dask –∫–ª–∞—Å—Ç–µ—Ä—É
                self.client = Client(scheduler_address)
                print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ Dask –∫–ª–∞—Å—Ç–µ—Ä—É: {scheduler_address}")
                print(f"Dashboard: {self.client.dashboard_link}")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Dask –∫–ª–∞—Å—Ç–µ—Ä—É: {e}")
                print("–ò—Å–ø–æ–ª—å–∑—É—é –ª–æ–∫–∞–ª—å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è")
                self.use_dask_cluster = False
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        if self.use_dask_cluster:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ—Ä–µ–∑ Dask –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            self.df = dd.read_csv(
                input_file,
                parse_dates=['TRADEDATE'],
                dtype={
                    'SECID': 'object',
                    'TRADE_SESSION_DATE': 'object'  # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç—É —Å—Ç—Ä–æ–∫—É
                },
                blocksize='64MB'
            )

            print(f"–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —á–µ—Ä–µ–∑ Dask: {self.df.npartitions} –ø–∞—Ä—Ç–∏—Ü–∏–π")
        else:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —á–µ—Ä–µ–∑ pandas
            self.df = pd.read_csv(input_file, parse_dates=['TRADEDATE'])
            print(f"–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —á–µ—Ä–µ–∑ Pandas: {len(self.df)} —Å—Ç—Ä–æ–∫")
    
    def clean_data(self):
        """–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        print("–û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        if self.use_dask_cluster:
            # Dask –≤–µ—Ä—Å–∏—è
            self.df = self.df.dropna(subset=['CLOSE', 'OPEN', 'HIGH', 'LOW', 'VOLUME'])
            self.df = self.df.drop_duplicates(subset=['TRADEDATE', 'SECID'])
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –≤ Dask
            self.df = self.df.set_index('TRADEDATE').reset_index()
        else:
            # Pandas –≤–µ—Ä—Å–∏—è
            self.df = self.df.dropna(subset=['CLOSE', 'OPEN', 'HIGH', 'LOW', 'VOLUME'])
            self.df = self.df.drop_duplicates(subset=['TRADEDATE', 'SECID'])
            self.df = self.df.sort_values(['SECID', 'TRADEDATE'])
        
        return self
    
    def calculate_indicators(self):
        """–†–∞—Å—á–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        print("–†–∞—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤...")
        
        if self.use_dask_cluster:
            # –î–ª—è Dask: –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ pandas –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
            # (rolling –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ Dask —Å–ª–æ–∂–Ω—ã, –ø–æ—ç—Ç–æ–º—É –¥–µ–ª–∞–µ–º compute)
            print("‚ö†Ô∏è –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ Pandas –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤...")
            df_pandas = self.df.compute()
            
            def calculate_for_security(group):
                group = group.sort_values('TRADEDATE')
                
                group['DAILY_RETURN'] = group['CLOSE'].pct_change() * 100
                group['MA_7'] = group['CLOSE'].rolling(window=7, min_periods=1).mean()
                group['MA_30'] = group['CLOSE'].rolling(window=30, min_periods=1).mean()
                group['VOLATILITY_7'] = group['DAILY_RETURN'].rolling(window=7, min_periods=1).std()
                group['VOLUME_CHANGE'] = group['VOLUME'].pct_change() * 100
                
                return group
            
            df_pandas = df_pandas.groupby('SECID', group_keys=False).apply(calculate_for_security)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ Dask —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–∞—Ä—Ç–∏—Ü–∏–π
            self.df = dd.from_pandas(df_pandas, npartitions=10)
            print(f"‚úÖ –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã, —Å–æ–∑–¥–∞–Ω–æ {self.df.npartitions} –ø–∞—Ä—Ç–∏—Ü–∏–π")
            
        else:
            # Pandas –≤–µ—Ä—Å–∏—è (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
            def calculate_for_security(group):
                group = group.sort_values('TRADEDATE')
                
                group['DAILY_RETURN'] = group['CLOSE'].pct_change() * 100
                group['MA_7'] = group['CLOSE'].rolling(window=7, min_periods=1).mean()
                group['MA_30'] = group['CLOSE'].rolling(window=30, min_periods=1).mean()
                group['VOLATILITY_7'] = group['DAILY_RETURN'].rolling(window=7, min_periods=1).std()
                group['VOLUME_CHANGE'] = group['VOLUME'].pct_change() * 100
                
                return group
            
            self.df = self.df.groupby('SECID', group_keys=False).apply(calculate_for_security)
        
        return self
    
    def aggregate_weekly(self):
        """–ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –Ω–µ–¥–µ–ª—è–º"""
        print("–ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ –Ω–µ–¥–µ–ª—è–º...")
        
        if self.use_dask_cluster:
            # Compute –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ü–∏–∏
            df_computed = self.df.compute()
        else:
            df_computed = self.df.copy()
        
        df_computed.set_index('TRADEDATE', inplace=True)
        
        weekly = df_computed.groupby('SECID').resample('W').agg({
            'OPEN': 'first',
            'HIGH': 'max',
            'LOW': 'min',
            'CLOSE': 'last',
            'VOLUME': 'sum',
            'DAILY_RETURN': 'mean',
            'VOLATILITY_7': 'mean'
        }).reset_index()
        
        if not self.use_dask_cluster:
            self.df.reset_index(inplace=True)
        
        return weekly
    
    def save_results(self, daily_output, weekly_output=None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        print("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
        
        if self.use_dask_cluster:
            # –î–ª—è Dask: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Dask (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)...")
            
            # Compute –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
            df_computed = self.df.compute()
            df_computed.to_csv(daily_output, index=False)
            
            print(f"‚úÖ –î–Ω–µ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {daily_output}")
        else:
            # Pandas –≤–µ—Ä—Å–∏—è
            self.df.to_csv(daily_output, index=False)
            print(f"‚úÖ –î–Ω–µ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {daily_output}")
    
    def get_statistics(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        if self.use_dask_cluster:
            stats = {
                'total_rows': len(self.df),
                'partitions': self.df.npartitions,
                'memory_usage': self.df.memory_usage(deep=True).sum().compute() / 1024**2,
                'cluster_info': str(self.client) if self.client else 'No cluster'
            }
        else:
            stats = {
                'total_rows': len(self.df),
                'partitions': 1,
                'memory_usage': self.df.memory_usage(deep=True).sum() / 1024**2,
                'cluster_info': 'Local pandas'
            }
        
        return stats
    
    def close(self):
        """–ó–∞–∫—Ä—ã—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –∫–ª–∞—Å—Ç–µ—Ä–æ–º"""
        if self.client:
            self.client.close()
            print("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Dask –∫–ª–∞—Å—Ç–µ—Ä–æ–º –∑–∞–∫—Ä—ã—Ç–æ")


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    import sys
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    use_cluster = '--cluster' in sys.argv
    scheduler = 'localhost:8786' if use_cluster else None
    
    if use_cluster:
        print("üöÄ –ó–∞–ø—É—Å–∫ —Å Dask –∫–ª–∞—Å—Ç–µ—Ä–æ–º")
    else:
        print("üêº –ó–∞–ø—É—Å–∫ —Å –ª–æ–∫–∞–ª—å–Ω—ã–º Pandas")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    processor = MOEXDataProcessor(
        'data/moex_raw_data.csv',
        use_dask_cluster=use_cluster,
        scheduler_address=scheduler
    )
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞
    processor.clean_data()
    processor.calculate_indicators()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = processor.get_statistics()
    print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    processor.save_results(
        daily_output='data/moex_processed_daily.csv'
    )
    
    # –ê–≥—Ä–µ–≥–∞—Ü–∏—è
    weekly_df = processor.aggregate_weekly()
    weekly_df.to_csv('data/moex_processed_weekly.csv', index=False)
    
    print("\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    
    # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
    processor.close()